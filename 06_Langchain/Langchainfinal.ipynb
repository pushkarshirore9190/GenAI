{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "865f70ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain.llms import OpenAI\n",
    "os.environ['OPENAI_API_KEY'] = 'sk-'\n",
    "llm = OpenAI(temperature = 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b82bc0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The capital of India is New Delhi.\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke(\"What is the capital of india\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71523d9",
   "metadata": {},
   "source": [
    "# Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1d8a0d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of India is New Delhi.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"Question: whats the capital of india\n",
    "\n",
    "Answer: \"\"\"\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99c535dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b6ad90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5719d465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Question: whats the capital of india\\n\\nAnswer: '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.format(question=\"whats the capital of india\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2270f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: whats the capital of india\n",
      "\n",
      "Answer: \n"
     ]
    }
   ],
   "source": [
    "prm_str : str = prompt.format(question=\"whats the capital of india\")\n",
    "print(prm_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a728eac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The capital of India is New Delhi. '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prm_strr : str = prompt.format(question=\"whats the capital of india\")\n",
    "llm.invoke(prm_strr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acead03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whats the capital of india\n"
     ]
    }
   ],
   "source": [
    "promptt = PromptTemplate(\n",
    "    input_variables =['country'],\n",
    "    template = \"whats the capital of {country}\"\n",
    ")\n",
    "p = promptt.format(country=\"india\")\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5bc68a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The capital of India is New Delhi.\n"
     ]
    }
   ],
   "source": [
    "print(llm.invoke(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d13221",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e169dc60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "340e7b31",
   "metadata": {},
   "source": [
    "# Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43d374d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'country': 'Nepal', 'text': '\\n\\nThe capital of Nepal is Kathmandu.'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "chain = LLMChain(llm=llm, prompt=promptt)\n",
    "chain.invoke(\"Nepal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7f581a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nThe capital of Nepal is Kathmandu.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"Nepal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f8c95dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mwhats the capital of Nepal\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nThe capital of Nepal is Kathmandu.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = LLMChain(llm=llm, prompt=promptt, verbose=True)\n",
    "chain.run(\"Nepal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4822885b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(chain.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8029dccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(chain.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c436518",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345eaf24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ecd1165",
   "metadata": {},
   "source": [
    "# Simple Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99bae0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_food = PromptTemplate(\n",
    "    input_variables = ['place'],\n",
    "    template=\"\"\"suggest some most famous food items of {place}\"\"\"\n",
    ")\n",
    "\n",
    "food_chain = LLMChain(llm=llm, prompt=prompt_food)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7100865d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "schain = SimpleSequentialChain(chains = [chain, food_chain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f567615a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mwhats the capital of India\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " Some famous food items from New Delhi are:\n",
      "\n",
      "1. Butter Chicken - A creamy and rich chicken dish cooked in a tomato-based gravy, often served with naan or rice.\n",
      "\n",
      "2. Chole Bhature - A popular street food dish consisting of spicy chickpeas (chole) and fried bread (bhature).\n",
      "\n",
      "3. Aloo Chaat - A tangy and savory snack made with fried potatoes, spices, and chutney.\n",
      "\n",
      "4. Dahi Bhalla - A refreshing dish made with lentil fritters soaked in yogurt and topped with chutneys and spices.\n",
      "\n",
      "5. Parathas - A type of flatbread that can be stuffed with various fillings like potatoes, paneer, or vegetables.\n",
      "\n",
      "6. Gol Gappa - Also known as pani puri, this is a popular street food dish consisting of crispy hollow shells filled with spiced water and other ingredients.\n",
      "\n",
      "7. Biryani - A flavorful and aromatic rice dish cooked with meat or vegetables and spices.\n",
      "\n",
      "8. Kulfi - A traditional Indian ice cream made with milk, sugar, and various flavors like pistachio, mango, or rose.\n",
      "\n",
      "9. Samosas - Deep-fried triangular pastries filled with savory fillings like potatoes, peas, or meat.\n",
      "\n",
      "10.\n"
     ]
    }
   ],
   "source": [
    "ans = schain.run(\"India\")\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f249980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mwhats the capital of nepal\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " Some of the most famous food items in Kathmandu include:\n",
      "\n",
      "1. Momo: These are steamed or fried dumplings filled with meat or vegetables, and are a popular snack or appetizer in Kathmandu.\n",
      "\n",
      "2. Dal bhat: This is the national dish of Nepal and consists of lentil soup (dal) and steamed rice (bhat), often served with vegetables, pickles, and achar (spicy condiment).\n",
      "\n",
      "3. Newari cuisine: The Newari community in Kathmandu has a unique cuisine that includes dishes like bara (a lentil pancake), choila (marinated meat), and yomari (a sweet dumpling).\n",
      "\n",
      "4. Sel roti: This is a traditional Nepali snack made from rice flour and deep-fried in circular shapes. It is often served during festivals and special occasions.\n",
      "\n",
      "5. Thukpa: This is a hearty noodle soup that originated in Tibet but is also popular in Kathmandu. It usually contains vegetables, meat, and spices.\n",
      "\n",
      "6. Samosas: These are deep-fried or baked savory pastries filled with spiced potatoes, vegetables, or meat. They are a popular street food in Kathmandu.\n",
      "\n",
      "7. Chatamari: This is a\n"
     ]
    }
   ],
   "source": [
    "ans = schain.run(\"nepal\")\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10378d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mwhats the capital of china\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      ", China\n",
      "\n",
      "1. Peking Duck: This iconic dish of Beijing is a must-try for visitors. The crispy, roasted duck is served with thin pancakes, scallions, and plum sauce.\n",
      "\n",
      "2. Hotpot: This communal dish consists of a simmering pot of broth in which various meats, vegetables, and noodles are cooked. It is a popular choice for gatherings with friends and family.\n",
      "\n",
      "3. Dumplings (Jiaozi): These boiled or steamed pockets of dough filled with meat or vegetables are a staple in Beijing cuisine. They can be found in many variations, including pork, beef, and vegetarian options.\n",
      "\n",
      "4. Zhajiangmian: This dish consists of noodles topped with a thick sauce made from fermented soybean paste, minced meat, and vegetables. It is a popular and affordable street food in Beijing.\n",
      "\n",
      "5. Mongolian Hotpot: This dish originated in Beijing and is now popular throughout China. It consists of a spicy broth in which thinly sliced meats and vegetables are cooked.\n",
      "\n",
      "6. Beijing Noodles (Zha Jiang Mian): This dish is made with thick wheat noodles, topped with a sauce made from soybean paste, minced meat, and vegetables.\n",
      "\n",
      "7. Fried Scorpions: A popular street food in Beijing, sc\n"
     ]
    }
   ],
   "source": [
    "ans = schain.run(\"china\")\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26760e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0a6366",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb7ee64f",
   "metadata": {},
   "source": [
    "# Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "375e7c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "promptt = PromptTemplate(\n",
    "    input_variables =['country'],\n",
    "    template = \"whats the capital of {country}\"\n",
    ")\n",
    "\n",
    "chain1 = LLMChain(llm=llm, prompt=promptt, output_key=\"capital\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "92434915",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_food = PromptTemplate(\n",
    "    input_variables = ['capital'],\n",
    "    template=\"\"\"suggest some most famous food items of {capital}\"\"\"\n",
    ")\n",
    "\n",
    "chain2 = LLMChain(llm=llm, prompt=prompt_food, output_key=\"food\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f8a5109c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_chain = SequentialChain(\n",
    "    chains = [chain1, chain2],\n",
    "    input_variables = ['country'],\n",
    "    output_variables = ['capital', 'food']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1835fb55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'country': 'India',\n",
       " 'capital': '\\n\\nThe capital of India is New Delhi.',\n",
       " 'food': ' Some of the most famous food items in New Delhi are:\\n\\n1. Butter Chicken: A popular North Indian dish made with succulent pieces of chicken cooked in a creamy, buttery tomato-based gravy.\\n\\n2. Chole Bhature: A popular street food dish consisting of spicy chickpea curry (chole) served with fried bread (bhature).\\n\\n3. Aloo Paratha: A popular breakfast dish consisting of a flatbread stuffed with spiced mashed potatoes and served with butter, pickles, and yogurt.\\n\\n4. Dahi Bhalla: A popular snack dish made with lentil fritters soaked in yogurt and topped with tangy chutneys.\\n\\n5. Gol Gappe: Also known as pani puri, these crispy hollow spheres filled with spicy water and served with various toppings are a popular street food in Delhi.\\n\\n6. Dal Makhani: A rich and creamy lentil dish made with black lentils, kidney beans, and butter, often served with rice or naan.\\n\\n7. Tandoori Chicken: A popular dish made with marinated chicken cooked in a clay oven (tandoor) and served with mint chutney.\\n\\n8. Aloo Tikki: A popular snack made with mashed potatoes and spices, formed into patt'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_chain({\"country\": \"India\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0b642abb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'country': 'India',\n",
       " 'capital': '\\n\\nThe capital of India is New Delhi.',\n",
       " 'food': ' Here are some of the most famous food items from Delhi:\\n\\n1. Butter Chicken - A rich and creamy chicken dish cooked in a tomato and butter-based gravy.\\n\\n2. Chole Bhature - A popular street food consisting of spicy chickpea curry and fried bread.\\n\\n3. Aloo Tikki - Fried potato patties served with chutney and toppings like yogurt, onions, and coriander.\\n\\n4. Parathas - Flaky, stuffed flatbreads usually filled with potatoes, paneer, or vegetables.\\n\\n5. Dahi Bhalla - Fried lentil dumplings served with yogurt, chutney, and spices.\\n\\n6. Golgappe (Pani Puri) - Small, crispy shells filled with spiced potato and tangy water.\\n\\n7. Biryani - A flavorful rice dish cooked with meat or vegetables and spices.\\n\\n8. Nihari - A slow-cooked meat stew with a rich and spicy gravy.\\n\\n9. Kebabs - Grilled meat or vegetable skewers marinated in spices and served with chutney.\\n\\n10. Rabri - A sweet dessert made with condensed milk, sugar, and nuts.'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_chain.invoke({\"country\": \"India\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2c17a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6924b62c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab66608",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c99865d",
   "metadata": {},
   "source": [
    "# ConversationChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06444fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "{history}\n",
      "Human: {input}\n",
      "AI:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use RunnableWithMessageHistory: https://api.python.langchain.com/en/latest/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "\n",
    "convo = ConversationChain(llm=llm)\n",
    "print(convo.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "241485e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" The capital of India is New Delhi. It is located in the northern part of the country and has a population of over 21 million people. New Delhi is also known for its rich history and cultural landmarks such as the Red Fort, Humayun's Tomb, and the Lotus Temple. It is also home to many government buildings, including the Parliament House and the Presidential Palace.\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.run(\"whats the capital of India?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a49a163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" The capital of Nepal is Kathmandu. It is situated in the central part of the country and has a population of over 1.5 million people. Kathmandu is known for its beautiful temples and pagodas, including the famous Pashupatinath Temple and Boudhanath Stupa. It is also the center of Nepal's economy, culture, and government, with many important institutions and landmarks located there.\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.run(\"whats the capital of Nepal?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f73736a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: whats the capital of India?\n",
      "AI:  The capital of India is New Delhi. It is located in the northern part of the country and has a population of over 21 million people. New Delhi is also known for its rich history and cultural landmarks such as the Red Fort, Humayun's Tomb, and the Lotus Temple. It is also home to many government buildings, including the Parliament House and the Presidential Palace.\n",
      "Human: whats the capital of Nepal?\n",
      "AI:  The capital of Nepal is Kathmandu. It is situated in the central part of the country and has a population of over 1.5 million people. Kathmandu is known for its beautiful temples and pagodas, including the famous Pashupatinath Temple and Boudhanath Stupa. It is also the center of Nepal's economy, culture, and government, with many important institutions and landmarks located there.\n"
     ]
    }
   ],
   "source": [
    "print(convo.memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1bf79b55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain.memory.buffer.ConversationBufferMemory"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(convo.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d884f30c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38b84411",
   "metadata": {},
   "source": [
    "# Chat Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "58a8b2a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "chat = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1b19558f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I speak Marathi, as it is the primary language spoken in Maharashtra.\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema.messages import HumanMessage, SystemMessage\n",
    "messages = [\n",
    "    SystemMessage(content=\"You live in Maharashtra\"),\n",
    "    HumanMessage(content=\"what language you speak\"),\n",
    "]\n",
    "response = chat.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0188b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08508473",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "366636ce",
   "metadata": {},
   "source": [
    "# Pydantic Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6cfc0e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.pydantic_v1 import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "885fd14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QA(BaseModel):\n",
    "    Question: str = Field(description=\"frame a question on given query\")\n",
    "    Answer: str = Field(description=\"answer of that question\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "92c29745",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = PydanticOutputParser(pydantic_object=QA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "996047ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "61a68300",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"computer science\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b2d51963",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm = prompt | llm\n",
    "output = pm.invoke({\"query\": query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d1d5ce6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{\n",
      "    \"Question\": \"What is computer science?\",\n",
      "    \"Answer\": \"Computer science is the study of computers and computational systems, including their principles, their hardware and software designs, their applications, and their impact on society.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c3802ceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b893783",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f66dd862",
   "metadata": {},
   "source": [
    "# CommaSeparated List OutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "85d0c700",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import CommaSeparatedListOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "744b3d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = CommaSeparatedListOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "74f3acc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "format_instructions = output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5b3db790",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=\"List five {subject}.\\n{format_instructions}\",\n",
    "    input_variables=[\"subject\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "16fc6782",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"IPL Teams\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d61892d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "output = llm(prompt.format(subject=query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2c0f08de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mumbai Indians', 'Chennai Super Kings', 'Kolkata Knight Riders', 'Royal Challengers Bangalore', 'Delhi Capitals']\n"
     ]
    }
   ],
   "source": [
    "parsed_result = output_parser.parse(output)\n",
    "print(parsed_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9b503413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(parsed_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a82235",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f8ad103",
   "metadata": {},
   "source": [
    "# Datetime Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "aae5ac3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import DatetimeOutputParser\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "82704a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = DatetimeOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "94d3633a",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Answer the user's question:\n",
    "{question}\n",
    "{format_instructions}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c55eded0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(\n",
    "    template,\n",
    "    partial_variables={\"format_instructions\": output_parser.get_format_instructions()},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6bd3fe64",
   "metadata": {},
   "outputs": [],
   "source": [
    "chainn = LLMChain(prompt=prompt, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4f2df26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"when was chandrayan launched\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b979473b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = chainn.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "016a9514",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_result = output_parser.parse(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2b4560c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2008-10-22 00:00:00\n"
     ]
    }
   ],
   "source": [
    "print(parsed_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d06cfeae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(parsed_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1aae03b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c92b29a",
   "metadata": {},
   "source": [
    "# Text File Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0bf8f6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"hello.txt\")\n",
    "document = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "41ebe272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'hello.txt'}, page_content='Hello and Welcome Dosto to 5 Minutes Engineering')]\n"
     ]
    }
   ],
   "source": [
    "print(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1b3f8c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello and Welcome Dosto to 5 Minutes Engineering\n"
     ]
    }
   ],
   "source": [
    "print(document[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408825c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "873162c5",
   "metadata": {},
   "source": [
    "# CSV Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5362e46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "loader = CSVLoader(file_path='employee.csv')\n",
    "document1 = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "932ad670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'employee.csv', 'row': 0}, page_content='emp_id: 1\\nemp_name: shridhar\\nlocation: maharashtra\\njoining_date: 2022\\nscore: 9.2\\njob_domain: marketing\\nlanguage_id: 4'), Document(metadata={'source': 'employee.csv', 'row': 1}, page_content='emp_id: 2\\nemp_name: rajendra\\nlocation: punjab\\njoining_date: 2021\\nscore: 7.3\\njob_domain: web development\\nlanguage_id: 3'), Document(metadata={'source': 'employee.csv', 'row': 2}, page_content='emp_id: 3\\nemp_name: manisha\\nlocation: maharashtra\\njoining_date: 2013\\nscore: 6\\njob_domain: Sales\\nlanguage_id: 4'), Document(metadata={'source': 'employee.csv', 'row': 3}, page_content='emp_id: 4\\nemp_name: pooja\\nlocation: punjab\\njoining_date: 2023\\nscore: 5\\njob_domain: web development\\nlanguage_id: 3'), Document(metadata={'source': 'employee.csv', 'row': 4}, page_content='emp_id: 5\\nemp_name: parth\\nlocation: maharashtra\\njoining_date: 2022\\nscore: 7\\njob_domain: web development\\nlanguage_id: 4'), Document(metadata={'source': 'employee.csv', 'row': 5}, page_content='emp_id: 6\\nemp_name: rajesh\\nlocation: gujrat\\njoining_date: 2000\\nscore: 9\\njob_domain: marketing\\nlanguage_id: 6'), Document(metadata={'source': 'employee.csv', 'row': 6}, page_content='emp_id: 7\\nemp_name: suresh\\nlocation: MP\\njoining_date: 2001\\nscore: 7\\njob_domain: marketing\\nlanguage_id: 1'), Document(metadata={'source': 'employee.csv', 'row': 7}, page_content='emp_id: 8\\nemp_name: mahesh\\nlocation: maharashtra\\njoining_date: 2009\\nscore: 8.4\\njob_domain: Sales\\nlanguage_id: 4'), Document(metadata={'source': 'employee.csv', 'row': 8}, page_content='emp_id: 9\\nemp_name: ravi\\nlocation: gujrat\\njoining_date: 2001\\nscore: 7.4\\njob_domain: web development\\nlanguage_id: 6'), Document(metadata={'source': 'employee.csv', 'row': 9}, page_content='emp_id: 10\\nemp_name: john\\nlocation: Goa\\njoining_date: 2015\\nscore: 7.2\\njob_domain: web development\\nlanguage_id: 2'), Document(metadata={'source': 'employee.csv', 'row': 10}, page_content='emp_id: 11\\nemp_name: adam\\nlocation: punjab\\njoining_date: 2000\\nscore: 9.3\\njob_domain: marketing\\nlanguage_id: 3'), Document(metadata={'source': 'employee.csv', 'row': 11}, page_content='emp_id: 12\\nemp_name: mohan\\nlocation: maharashtra\\njoining_date: 1999\\nscore: 8.8\\njob_domain: marketing\\nlanguage_id: 4'), Document(metadata={'source': 'employee.csv', 'row': 12}, page_content='emp_id: 13\\nemp_name: deepak\\nlocation: maharashtra\\njoining_date: 1998\\nscore: 8.6\\njob_domain: web development\\nlanguage_id: 4'), Document(metadata={'source': 'employee.csv', 'row': 13}, page_content='emp_id: 14\\nemp_name: mohit\\nlocation: maharashtra\\njoining_date: 1995\\nscore: 8\\njob_domain: marketing\\nlanguage_id: 4'), Document(metadata={'source': 'employee.csv', 'row': 14}, page_content='emp_id: 15\\nemp_name: sumer\\nlocation: Rajasthan\\njoining_date: 2000\\nscore: 8.5\\njob_domain: Sales\\nlanguage_id: 5'), Document(metadata={'source': 'employee.csv', 'row': 15}, page_content='emp_id: 16\\nemp_name: harry\\nlocation: maharashtra\\njoining_date: 1997\\nscore: 7.9\\njob_domain: Sales\\nlanguage_id: 4'), Document(metadata={'source': 'employee.csv', 'row': 16}, page_content='emp_id: 17\\nemp_name: sonal\\nlocation: gujrat\\njoining_date: 1946\\nscore: 8.6\\njob_domain: marketing\\nlanguage_id: 6'), Document(metadata={'source': 'employee.csv', 'row': 17}, page_content='emp_id: 18\\nemp_name: neil\\nlocation: maharashtra\\njoining_date: 2009\\nscore: 7.8\\njob_domain: finance\\nlanguage_id: 4'), Document(metadata={'source': 'employee.csv', 'row': 18}, page_content='emp_id: 19\\nemp_name: ankur\\nlocation: maharashtra\\njoining_date: 1972\\nscore: 9.2\\njob_domain: marketing\\nlanguage_id: 4'), Document(metadata={'source': 'employee.csv', 'row': 19}, page_content='emp_id: 20\\nemp_name: abhay\\nlocation: maharashtra\\njoining_date: 2008\\nscore: 9\\njob_domain: finance\\nlanguage_id: 4'), Document(metadata={'source': 'employee.csv', 'row': 20}, page_content='emp_id: 21\\nemp_name: swapnil\\nlocation: maharashtra\\njoining_date: 1990\\nscore: 9\\njob_domain: marketing\\nlanguage_id: 4'), Document(metadata={'source': 'employee.csv', 'row': 21}, page_content='emp_id: 22\\nemp_name: karan\\nlocation: Tamil nadu\\njoining_date: 2019\\nscore: 8.2\\njob_domain: Sales\\nlanguage_id: 5'), Document(metadata={'source': 'employee.csv', 'row': 22}, page_content='emp_id: 23\\nemp_name: arjun\\nlocation: maharashtra\\njoining_date: 2019\\nscore: 8.5\\njob_domain: marketing\\nlanguage_id: 4'), Document(metadata={'source': 'employee.csv', 'row': 23}, page_content='emp_id: 24\\nemp_name: paresh\\nlocation: maharashtra\\njoining_date: 2019\\nscore: 8.4\\njob_domain: web development\\nlanguage_id: 4'), Document(metadata={'source': 'employee.csv', 'row': 24}, page_content='emp_id: 25\\nemp_name: jaggi\\nlocation: punjab\\njoining_date: 2010\\nscore: 8\\njob_domain: marketing\\nlanguage_id: 3')]\n"
     ]
    }
   ],
   "source": [
    "print(document1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c235421d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(document1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "810f58b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': 'employee.csv', 'row': 0}\n"
     ]
    }
   ],
   "source": [
    "print(document1[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ee12610d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': 'employee.csv', 'row': 1}\n"
     ]
    }
   ],
   "source": [
    "print(document1[1].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f383bbe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emp_id: 1\n",
      "emp_name: shridhar\n",
      "location: maharashtra\n",
      "joining_date: 2022\n",
      "score: 9.2\n",
      "job_domain: marketing\n",
      "language_id: 4\n"
     ]
    }
   ],
   "source": [
    "print(document1[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d1d855b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emp_id: 2\n",
      "emp_name: rajendra\n",
      "location: punjab\n",
      "joining_date: 2021\n",
      "score: 7.3\n",
      "job_domain: web development\n",
      "language_id: 3\n"
     ]
    }
   ],
   "source": [
    "print(document1[1].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fda70f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b5339fa",
   "metadata": {},
   "source": [
    "# PDF Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6ae658af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"Fitness.pdf\")\n",
    "doc = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7602ac6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'Fitness.pdf', 'page': 0}, page_content='SCHOOL OF\\nFITNESS SCIENCES'), Document(metadata={'source': 'Fitness.pdf', 'page': 1}, page_content='SCHOOL OF\\nFITNESS SCIENCES'), Document(metadata={'source': 'Fitness.pdf', 'page': 2}, page_content='SCHOOL OF\\nFITNESS SCIENCES'), Document(metadata={'source': 'Fitness.pdf', 'page': 3}, page_content='SCHOOL OF\\nFITNESS SCIENCES'), Document(metadata={'source': 'Fitness.pdf', 'page': 4}, page_content='SCHOOL OF\\nFITNESS SCIENCES'), Document(metadata={'source': 'Fitness.pdf', 'page': 5}, page_content='SCHOOL OF\\nFITNESS SCIENCES'), Document(metadata={'source': 'Fitness.pdf', 'page': 6}, page_content='SCHOOL OF\\nFITNESS SCIENCES')]\n"
     ]
    }
   ],
   "source": [
    "print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "05847dbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b8c7d4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': 'Fitness.pdf', 'page': 0}\n"
     ]
    }
   ],
   "source": [
    "print(doc[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4cd62e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCHOOL OF\n",
      "FITNESS SCIENCES\n"
     ]
    }
   ],
   "source": [
    "print(doc[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31359fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88121ebc",
   "metadata": {},
   "source": [
    "# Recursive Character TextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "dfc475e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "64b56b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\n\\n\", \"\\n\", ' ', ''],\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=0,\n",
    "    length_function=len,\n",
    "    add_start_index=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ce143d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "statement = \"With over 560k subscribers on YouTube, this accomplished individual stands at the intersection of education, technology, and digital influence. Holding a B.E. in Computer Engineering and an M.Tech from the prestigious College of Engineering, Pune, their academic prowess is complemented by a rich online presence. A TEDx Speaker and recipient of the coveted YouTube Silver Play Award, they skillfully navigate the realms of teaching, blogging, and podcasting. Through a dynamic blend of content creation and academic expertise, this educator continues to shape minds and foster a passion for learning across diverse platforms.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4a197a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='With over 560k subscribers on YouTube, this accomplished individual stands at the intersection of' metadata={'start_index': 0}\n",
      "page_content='education, technology, and digital influence. Holding a B.E. in Computer Engineering and an M.Tech' metadata={'start_index': 98}\n",
      "page_content='from the prestigious College of Engineering, Pune, their academic prowess is complemented by a rich' metadata={'start_index': 197}\n"
     ]
    }
   ],
   "source": [
    "split = text_splitter.create_documents([statement])\n",
    "print(split[0])\n",
    "print(split[1])\n",
    "print(split[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d11d0f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With over 560k subscribers on YouTube, this accomplished individual stands at the intersection of\n",
      "education, technology, and digital influence. Holding a B.E. in Computer Engineering and an M.Tech\n",
      "from the prestigious College of Engineering, Pune, their academic prowess is complemented by a rich\n"
     ]
    }
   ],
   "source": [
    "split = text_splitter.split_text(statement)\n",
    "print(split[0])\n",
    "print(split[1])\n",
    "print(split[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3868cd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7210275e",
   "metadata": {},
   "source": [
    "# Character Text Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e6331ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With over 560k subscribers on YouTube, this accomplished individual stands at the intersection of education, technology, and digital influence. Holding a B.E. in Computer Engineering and an M.Tech from the prestigious College of Engineering, Pune, their academic prowess is complemented by a rich online presence. A TEDx Speaker and recipient of the coveted YouTube Silver Play Award, they skillfully navigate the realms of teaching, blogging, and podcasting. Through a dynamic blend of content creation and academic expertise, this educator continues to shape minds and foster a passion for learning across diverse platforms.\n",
      "page_content='With over 560k subscribers on YouTube, this accomplished individual stands at the intersection of education, technology, and digital influence'\n",
      "page_content='Holding a B.E. in Computer Engineering and an M'\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "char_splitter = CharacterTextSplitter(\n",
    "    separator=\".\",\n",
    "    chunk_size=150,\n",
    "    chunk_overlap=0,\n",
    "    length_function=len,\n",
    ")\n",
    "\n",
    "print(statement)\n",
    "character = char_splitter.create_documents([statement])\n",
    "print(character[0])\n",
    "print(character[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8dbe7340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(character)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca126e98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a0678587",
   "metadata": {},
   "source": [
    "# Token Text Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d563983f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import TokenTextSplitter\n",
    "\n",
    "token_splitter = TokenTextSplitter(chunk_size=1,chunk_overlap=0)\n",
    "token = token_splitter.split_text(statement)\n",
    "print(token[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0189b9de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With over\n"
     ]
    }
   ],
   "source": [
    "token_splitter = TokenTextSplitter(chunk_size=2,chunk_overlap=0)\n",
    "token = token_splitter.split_text(statement)\n",
    "print(token[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "76318141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With over\n",
      " over 560\n"
     ]
    }
   ],
   "source": [
    "token_splitter = TokenTextSplitter(chunk_size=2,chunk_overlap=1)\n",
    "token = token_splitter.split_text(statement)\n",
    "print(token[0])\n",
    "print(token[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a40d8fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With over 560k subscribers on YouTube, this accomplished\n"
     ]
    }
   ],
   "source": [
    "token_splitter = TokenTextSplitter(chunk_size=10,chunk_overlap=0)\n",
    "token = token_splitter.split_text(statement)\n",
    "print(token[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2166e12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2de74c05",
   "metadata": {},
   "source": [
    "# Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4aab9d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "embeddings_model = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b39b43e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents embedded: 4\n"
     ]
    }
   ],
   "source": [
    "embeddings = embeddings_model.embed_documents(\n",
    "    [\"Hello ji\", \"kaise ho aap\", \"sab badiya ji\", \"lets learn langchain\"]\n",
    ")\n",
    "print(\"Number of documents embedded:\", len(embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "901b81d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.013063245759728398,\n",
       " -0.0010075740965801922,\n",
       " -0.018306410927566023,\n",
       " 0.003295016550322569,\n",
       " -0.02744587379609502,\n",
       " 0.030180840241439678,\n",
       " -0.02910884330582428,\n",
       " 0.014293293716635298,\n",
       " -0.007971260315555274,\n",
       " -0.0138534999348634,\n",
       " 0.02919130446528354,\n",
       " -0.005157267893903599,\n",
       " -0.003401529114121408,\n",
       " 0.003985630157777637,\n",
       " -0.002963453389586894,\n",
       " -0.002284865484301617,\n",
       " 0.034771187431230255,\n",
       " -0.017564258629787652,\n",
       " 0.03075806835765447,\n",
       " 0.005542087103708061,\n",
       " -0.011688891239429063,\n",
       " 0.006095265212567069,\n",
       " 0.00995033186786755,\n",
       " 0.0001642783967004427,\n",
       " -0.022731835798438085,\n",
       " 0.006005932289819541,\n",
       " 0.014210832557176043,\n",
       " -0.009579255718978366,\n",
       " -0.017619232736093823,\n",
       " 0.0002795953926604647,\n",
       " -0.004360141955480325,\n",
       " 0.017426823364022227,\n",
       " -0.01845759065123052,\n",
       " -0.017014517566725944,\n",
       " -0.003021863377537201,\n",
       " -0.01800405334288208,\n",
       " -0.0025923774735283423,\n",
       " 0.0063873158508105,\n",
       " 0.023982497648226006,\n",
       " 0.0007662030036260533,\n",
       " 0.04134060244804299,\n",
       " 0.0059372146569368275,\n",
       " -0.006940493959669508,\n",
       " 0.0018863025150899799,\n",
       " -0.019337178214774316,\n",
       " 0.005346241617161694,\n",
       " -0.005645164018693397,\n",
       " -0.0042295779873419035,\n",
       " -0.019131024384803647,\n",
       " 0.03199498947483344,\n",
       " 0.021329992362340604,\n",
       " 0.004978601582747278,\n",
       " -0.005253472579939398,\n",
       " -0.007675773562837075,\n",
       " -0.025975313658437357,\n",
       " 0.0036557848214487138,\n",
       " -0.006706853542207017,\n",
       " 0.02204465760696589,\n",
       " -0.0008563950714075894,\n",
       " -0.03430390566498274,\n",
       " -0.004404808184023456,\n",
       " -0.0051091655508857,\n",
       " -0.01317319490366327,\n",
       " 0.025425570732730586,\n",
       " -0.006191470364264134,\n",
       " -0.012431042605884901,\n",
       " 0.010383253420689912,\n",
       " -0.005981880885479959,\n",
       " 0.00666218684800262,\n",
       " 0.009379974117957232,\n",
       " 0.022718091340539013,\n",
       " 0.025741672775313598,\n",
       " -0.026318902754173455,\n",
       " -0.01254786304744678,\n",
       " 0.006370136209759189,\n",
       " -0.0098747420060353,\n",
       " -0.022154605819578232,\n",
       " -0.013296886642852154,\n",
       " -0.008108695581320702,\n",
       " -0.011791967223091868,\n",
       " 0.019295946703722158,\n",
       " -0.018759948235914464,\n",
       " -0.010053407851530355,\n",
       " 0.014471960493452885,\n",
       " 0.008184285443152951,\n",
       " 3.2312110125967887e-06,\n",
       " -0.013599244227536094,\n",
       " 0.028669048592729854,\n",
       " -0.0020890199977552505,\n",
       " -0.03644789953621353,\n",
       " 0.020271739884624284,\n",
       " -0.00955176866582528,\n",
       " 0.0015822264075073902,\n",
       " 0.012692170542161743,\n",
       " -0.017825386566064496,\n",
       " -0.0011853813791178208,\n",
       " -0.009565512192401824,\n",
       " 0.004655628242537259,\n",
       " 0.014389499333993628,\n",
       " -0.009297512958497975,\n",
       " -0.005428703242282216,\n",
       " -0.010871150011140975,\n",
       " -0.036282977217295016,\n",
       " 0.003121504178047768,\n",
       " -0.012960169776065593,\n",
       " -0.006342649156606104,\n",
       " -0.0017935334778676837,\n",
       " -0.010128997713362606,\n",
       " 0.0222095799258844,\n",
       " 0.012760888175044458,\n",
       " -0.015062933067566753,\n",
       " 0.028971408040058856,\n",
       " -0.007888799156096018,\n",
       " -0.03218739698425998,\n",
       " 0.019914406330989114,\n",
       " -0.007201621430285085,\n",
       " -0.0034169906979353345,\n",
       " 0.004535372152161877,\n",
       " -0.022594398670027598,\n",
       " -0.029878482656755734,\n",
       " 0.005548959332657598,\n",
       " -0.009599871474504446,\n",
       " 0.031060427804983474,\n",
       " -0.013984063903001822,\n",
       " 0.02910884330582428,\n",
       " -0.006964544898347825,\n",
       " 0.013509911770449832,\n",
       " -0.008170541916576408,\n",
       " -0.008837104352522527,\n",
       " -0.005280959633092484,\n",
       " 0.03697015540876721,\n",
       " -0.003872245830690527,\n",
       " -0.0037382462137386025,\n",
       " 0.0055523949814711,\n",
       " 0.000642511031606536,\n",
       " 0.013290014413902618,\n",
       " -0.003099171063776202,\n",
       " 0.025246905818558058,\n",
       " -0.006181162486501093,\n",
       " -0.009441820453212938,\n",
       " 0.010644381356966754,\n",
       " 0.01878743528906755,\n",
       " 0.008122439107897245,\n",
       " -0.02615397857260988,\n",
       " 0.0029548635690612385,\n",
       " 0.0055730102713359144,\n",
       " 0.006009367938633044,\n",
       " -0.016877082300960515,\n",
       " 0.004411679947311727,\n",
       " -0.01194314694675637,\n",
       " 0.0023948139297445916,\n",
       " -0.010287048734654112,\n",
       " 0.01167514771285252,\n",
       " -0.0029565816262986226,\n",
       " 0.015873802066905304,\n",
       " 0.008273617900239215,\n",
       " 0.016698415524142928,\n",
       " 0.018072770044442264,\n",
       " 0.0016921748529503647,\n",
       " -0.004738089401996515,\n",
       " -0.0020993276426876572,\n",
       " -0.0060128040531078125,\n",
       " 0.002540839248866307,\n",
       " -0.014471960493452885,\n",
       " 0.013118220797357099,\n",
       " 0.03479867262173828,\n",
       " 0.0055730102713359144,\n",
       " -0.009263153676395353,\n",
       " -0.006789314701666273,\n",
       " -0.0008555361009965555,\n",
       " 0.02659377328570431,\n",
       " 0.02609900446630371,\n",
       " -0.02460095727549296,\n",
       " -0.0045594235565014594,\n",
       " -0.014540678126335598,\n",
       " 0.006105573090330108,\n",
       " 0.007105416278588021,\n",
       " 0.004607525899519359,\n",
       " -0.013791654530930224,\n",
       " -0.013303757940479161,\n",
       " -0.033726675686122885,\n",
       " 0.006706853542207017,\n",
       " 0.012657811260059122,\n",
       " 0.024655931381799133,\n",
       " -0.00305106848792767,\n",
       " -0.013826012881710315,\n",
       " 0.0018416359373008995,\n",
       " -0.014691856918677568,\n",
       " 0.004531936037687109,\n",
       " -0.012905195669759421,\n",
       " 0.016602209906784602,\n",
       " 0.02688238827513424,\n",
       " 0.0006330623570851629,\n",
       " -0.022553169021620502,\n",
       " -0.6645282189241544,\n",
       " -0.037217537024499925,\n",
       " 0.019062305820598403,\n",
       " 0.00945556397978948,\n",
       " 0.01034889506990982,\n",
       " 0.005913163252597245,\n",
       " 0.008287361426815758,\n",
       " 0.030125866135133506,\n",
       " -0.013956576849848737,\n",
       " 0.01654723580047843,\n",
       " -0.024765881457056535,\n",
       " 0.023116654542581282,\n",
       " 0.0012601118630854301,\n",
       " 0.02035420104408354,\n",
       " 0.007380287275780141,\n",
       " -0.004236449750630175,\n",
       " 0.0005033575921884082,\n",
       " -0.00875464226174074,\n",
       " -0.036228003110988845,\n",
       " 0.0005072229881418899,\n",
       " -0.012108069265674882,\n",
       " 0.004452910992702621,\n",
       " -0.010307663558857661,\n",
       " 0.033589242283002516,\n",
       " 0.0009457281687780916,\n",
       " -0.019969380437295285,\n",
       " 0.034826161537536426,\n",
       " -0.007105416278588021,\n",
       " -0.015172881280179094,\n",
       " 0.034578776196513596,\n",
       " -0.017138208374592297,\n",
       " -0.0024566597993390337,\n",
       " 0.006294546813588204,\n",
       " -0.003642041294872171,\n",
       " 0.06019675816396084,\n",
       " -0.006761827648513187,\n",
       " -0.013716064669097973,\n",
       " 0.023515217744623552,\n",
       " 0.016863337843061443,\n",
       " 0.026937362381440406,\n",
       " -0.011139149245044822,\n",
       " -0.0036901436378900705,\n",
       " 0.0004183193759769046,\n",
       " -0.005153831779428831,\n",
       " 0.003858502304113984,\n",
       " 0.0035131953839711337,\n",
       " 0.0055764463858106825,\n",
       " -0.001034202237529902,\n",
       " 0.007469620664188934,\n",
       " 0.019831945171529856,\n",
       " -0.005689830712897793,\n",
       " -0.004545680029924917,\n",
       " -0.014224576083752586,\n",
       " 0.02200342609591373,\n",
       " -0.01237606849957873,\n",
       " -0.0010238945925974947,\n",
       " 0.015928776173211475,\n",
       " -7.864962014146014e-05,\n",
       " 0.02549428929693583,\n",
       " 0.01649226169417226,\n",
       " 0.03004340497567425,\n",
       " 0.009489922330569573,\n",
       " -0.009318127782701524,\n",
       " -0.025879108041079027,\n",
       " -0.00202373801368604,\n",
       " -0.0012549580406192265,\n",
       " -0.018017795938136093,\n",
       " -0.015887546524804376,\n",
       " 0.01175073664336224,\n",
       " -0.0044494748782278526,\n",
       " -0.015557700955644821,\n",
       " 0.003525221086140925,\n",
       " -0.017426823364022227,\n",
       " -0.0005424408332019388,\n",
       " 0.017179439885644455,\n",
       " 0.02379008827615441,\n",
       " 0.002228173320758062,\n",
       " -0.0038035279649771808,\n",
       " -0.010232074628347942,\n",
       " -0.00022676861051847675,\n",
       " 0.0007400043769856896,\n",
       " -0.0049339353542041465,\n",
       " -0.019790715523122757,\n",
       " -0.024078703265584336,\n",
       " 0.007112288041876293,\n",
       " -0.031417759495973585,\n",
       " -0.008802745070419905,\n",
       " 0.0049167557131528355,\n",
       " 0.0009878178353340701,\n",
       " 0.003009837908198042,\n",
       " 0.013138835621560648,\n",
       " 0.010204587575194856,\n",
       " 0.016794621141501258,\n",
       " -0.010493201633302253,\n",
       " -0.00642511031606536,\n",
       " 0.016066211438976904,\n",
       " -0.01885615385327279,\n",
       " 0.004092142721576476,\n",
       " 0.008218643793933044,\n",
       " 0.006858032334548987,\n",
       " 0.00970294745816725,\n",
       " -0.014609395759218312,\n",
       " 0.006421674667251857,\n",
       " 0.009634229825284536,\n",
       " 0.018375129491771267,\n",
       " 0.007105416278588021,\n",
       " -0.02794064075285056,\n",
       " 0.013331244993632247,\n",
       " 0.015928776173211475,\n",
       " -0.009331872240600596,\n",
       " 0.015461496269609023,\n",
       " 0.003362016358798531,\n",
       " -0.020917686565044325,\n",
       " 0.00940058987348331,\n",
       " -0.0066690586112908914,\n",
       " -0.03993876087459057,\n",
       " -0.011262840984233708,\n",
       " 0.03369919049561486,\n",
       " 0.018869896448526803,\n",
       " -0.015557700955644821,\n",
       " 0.021783529670689045,\n",
       " 0.005521471813843247,\n",
       " 0.016024981790569805,\n",
       " -0.0005334216147822536,\n",
       " -0.00277619749073555,\n",
       " 0.02710228470035892,\n",
       " -0.018869896448526803,\n",
       " -0.0048995760721015245,\n",
       " -0.010809303675885267,\n",
       " -0.008575976416245685,\n",
       " 0.0025167878445267245,\n",
       " -0.007668901799548804,\n",
       " 0.0026714029841740958,\n",
       " -0.015365290652250693,\n",
       " 0.030565658985582875,\n",
       " -0.018759948235914464,\n",
       " 0.01455442165291214,\n",
       " 0.007126031568452835,\n",
       " 0.008740898735164199,\n",
       " -0.01192253119123029,\n",
       " -0.018966102065885133,\n",
       " 0.013990936131951359,\n",
       " 0.0032761190848645066,\n",
       " 0.011627044904173356,\n",
       " 0.006744648007461876,\n",
       " -0.018402616544924352,\n",
       " -0.023721371574594224,\n",
       " 0.0005046460769087881,\n",
       " -0.009689203931590708,\n",
       " -0.009111974884053383,\n",
       " -0.011187251122401458,\n",
       " 0.000791972174164729,\n",
       " -0.007057313935570121,\n",
       " 0.02395501059507292,\n",
       " 0.017632977193992896,\n",
       " -0.007730748134804511,\n",
       " 0.002745274555938329,\n",
       " -0.010616894303813669,\n",
       " -0.02109635147921685,\n",
       " -0.018320155385465095,\n",
       " 0.016038724385823818,\n",
       " 0.020381688097236627,\n",
       " -0.0011458686237949443,\n",
       " -0.008039977948437988,\n",
       " 0.014760574551560282,\n",
       " -0.0009036385604297714,\n",
       " -0.007881926927146482,\n",
       " 0.007503979480630291,\n",
       " 0.002509916081238453,\n",
       " -0.035815695451047506,\n",
       " -0.0016165853403640633,\n",
       " 0.002290019423183137,\n",
       " -0.016217391162641405,\n",
       " 0.009538025139248738,\n",
       " 0.0019223792723534045,\n",
       " -0.01224550453144031,\n",
       " 0.00995033186786755,\n",
       " -0.009111974884053383,\n",
       " -0.010458843282522163,\n",
       " -0.014540678126335598,\n",
       " -0.010342022840960283,\n",
       " -0.01783913102396357,\n",
       " -0.015337803599097607,\n",
       " 0.017784156917657397,\n",
       " 0.0278581795933913,\n",
       " 0.015007958961260582,\n",
       " -0.006188034249789365,\n",
       " 0.03034576256035819,\n",
       " -0.0031043247698270895,\n",
       " 0.010651252654593761,\n",
       " 0.0006154534345551384,\n",
       " 0.014691856918677568,\n",
       " -0.02530187992486423,\n",
       " -0.01573636680113988,\n",
       " 0.0011913941137874002,\n",
       " -0.019886919277836028,\n",
       " 0.018031540396035165,\n",
       " 0.006974852776110865,\n",
       " 0.015488983322762108,\n",
       " 0.011125405718468281,\n",
       " 0.024436034956574447,\n",
       " 0.003985630157777637,\n",
       " 0.042934855256212066,\n",
       " -0.00045525516185902136,\n",
       " -0.014540678126335598,\n",
       " -0.013832885110659852,\n",
       " 0.0038035279649771808,\n",
       " -0.029383713837355135,\n",
       " 0.02526064841381207,\n",
       " 0.033121960516755006,\n",
       " -0.006964544898347825,\n",
       " 0.0006171713753772062,\n",
       " 0.003995937569879412,\n",
       " -0.004425423939549535,\n",
       " 0.022965474818916785,\n",
       " 0.014155858450869871,\n",
       " -0.011627044904173356,\n",
       " 0.021536146192311277,\n",
       " -0.02905386919951811,\n",
       " -0.025054494583841402,\n",
       " 0.005744804819203964,\n",
       " -0.00024308907743195033,\n",
       " -0.02410619031873742,\n",
       " -0.017811643970810483,\n",
       " 0.00293768416084056,\n",
       " 0.010259561681501028,\n",
       " 0.01070622676089993,\n",
       " 0.022415733755855073,\n",
       " 0.006586597451831635,\n",
       " -0.0072634672998795275,\n",
       " -0.028861459827446513,\n",
       " 0.020821480947685995,\n",
       " -0.012348581446425646,\n",
       " 0.026483825073091966,\n",
       " -0.010376382123062905,\n",
       " 0.011414019776575678,\n",
       " 0.009888485532611842,\n",
       " -0.03064812014504213,\n",
       " 0.02170106851122979,\n",
       " -0.011613301377596813,\n",
       " 0.002097609585450273,\n",
       " 0.02115132558552302,\n",
       " 0.018416359140178362,\n",
       " -0.01355114235017946,\n",
       " 0.005359985143738237,\n",
       " 0.02700607908300059,\n",
       " 0.016574722853631516,\n",
       " -0.007964388086605738,\n",
       " -0.016327339375253744,\n",
       " 0.039334045705222684,\n",
       " -0.010610022074864132,\n",
       " -0.0027006078617339327,\n",
       " -0.008795872841470369,\n",
       " -0.002229891377995446,\n",
       " 0.024669675839698205,\n",
       " -0.02194845198960756,\n",
       " -0.013805398057506767,\n",
       " 0.013049502233151855,\n",
       " 0.008177413214203415,\n",
       " 0.02609900446630371,\n",
       " -0.006476648773558028,\n",
       " 0.0074833641907654765,\n",
       " 0.017674208705045054,\n",
       " 0.00011359904786199686,\n",
       " 0.021220044149728265,\n",
       " -0.008424797623903715,\n",
       " 0.0010393560599961053,\n",
       " -0.0018914563375561832,\n",
       " 0.004342962314429014,\n",
       " -0.012575350100599866,\n",
       " -0.021604862893871462,\n",
       " -0.007758235187957597,\n",
       " 0.00970294745816725,\n",
       " -0.010225202399398406,\n",
       " 0.019076050278497476,\n",
       " -0.000298922256012557,\n",
       " 0.025906595094232113,\n",
       " 0.005112601199699203,\n",
       " 0.005270652220990709,\n",
       " -0.007119159805164564,\n",
       " -0.026030287764743525,\n",
       " -0.007284082589744342,\n",
       " 0.011414019776575678,\n",
       " 0.018622512970149035,\n",
       " -0.003872245830690527,\n",
       " -0.019570817235253016,\n",
       " -0.027734486922879886,\n",
       " -0.012272991584593395,\n",
       " -0.003971886631201094,\n",
       " 0.027789462891831117,\n",
       " -0.00772387637151624,\n",
       " 0.015571444482221364,\n",
       " 0.01232109439327256,\n",
       " -0.01836138503387219,\n",
       " -0.015007958961260582,\n",
       " 0.024669675839698205,\n",
       " 0.032544730537895146,\n",
       " -0.004136808950119608,\n",
       " 0.006222393066230722,\n",
       " 0.0055627028592341405,\n",
       " 0.010761200867206102,\n",
       " 0.010410740473842998,\n",
       " -0.009929716112341471,\n",
       " -0.027775718433932044,\n",
       " 0.009050128548797675,\n",
       " 0.003465093040953234,\n",
       " -0.01455442165291214,\n",
       " -0.014052781535884535,\n",
       " 0.012211146180660217,\n",
       " -0.012341709217476108,\n",
       " -0.019886919277836028,\n",
       " -0.00934561576717714,\n",
       " -0.013647347036215259,\n",
       " -0.011709506063632613,\n",
       " -0.010795560149308724,\n",
       " 0.0020615327117715324,\n",
       " -0.017619232736093823,\n",
       " 0.007833825049789847,\n",
       " 0.0227455783936921,\n",
       " -0.020670301224021494,\n",
       " -0.00955176866582528,\n",
       " -0.01595626322636456,\n",
       " -0.020477891851949894,\n",
       " 0.010610022074864132,\n",
       " 0.0751497411562702,\n",
       " 0.006858032334548987,\n",
       " -0.01370232114252143,\n",
       " -0.007469620664188934,\n",
       " -0.0017935334778676837,\n",
       " 0.017591745682940738,\n",
       " -0.03501856904696296,\n",
       " -0.023116654542581282,\n",
       " 0.0012781502999248007,\n",
       " -0.016574722853631516,\n",
       " 0.005067934971156071,\n",
       " -0.023212860159939612,\n",
       " -0.0024394803911183555,\n",
       " 0.0054012157234678655,\n",
       " 0.009641102054234074,\n",
       " -0.001517803568472188,\n",
       " 0.0039478352268615124,\n",
       " -0.012857092861080256,\n",
       " 0.018265181279158924,\n",
       " 0.016176161514234306,\n",
       " 0.01392908979669565,\n",
       " -0.004803371386065726,\n",
       " 0.02910884330582428,\n",
       " 0.008555360660719605,\n",
       " -0.0002763742390671729,\n",
       " 0.026937362381440406,\n",
       " 0.025246905818558058,\n",
       " 0.030290788454052017,\n",
       " 0.004545680029924917,\n",
       " -0.01455442165291214,\n",
       " 0.011620173606546349,\n",
       " 0.00705044217228185,\n",
       " -0.004391064657446913,\n",
       " 0.0012309068691102767,\n",
       " -0.008431668921530721,\n",
       " 0.02390003648876675,\n",
       " 0.0028431972992115123,\n",
       " 0.0057173177660508785,\n",
       " -0.001147586564617012,\n",
       " 0.013015143882371762,\n",
       " 0.026373876860479626,\n",
       " 0.02094517361819741,\n",
       " 0.00236389099494737,\n",
       " -0.006294546813588204,\n",
       " 0.015090420120719839,\n",
       " 0.0010238945925974947,\n",
       " -0.0138534999348634,\n",
       " 0.029850995603602652,\n",
       " -0.01216991560093059,\n",
       " -0.0012154454017116662,\n",
       " 0.030868018432911874,\n",
       " 0.010603150777237126,\n",
       " -0.01730313255615587,\n",
       " 0.007916286209249104,\n",
       " 0.011936274717806832,\n",
       " 0.03215991179375195,\n",
       " -0.026428850966785798,\n",
       " -0.024064958807685263,\n",
       " -0.010280176505704576,\n",
       " -0.0020941737038061375,\n",
       " -0.009448691750839944,\n",
       " -0.019529587586845917,\n",
       " -0.01914476698005766,\n",
       " -0.005263780457702438,\n",
       " -0.018979844661139146,\n",
       " -0.03839948589801778,\n",
       " -0.009441820453212938,\n",
       " -0.023858806840359653,\n",
       " -0.010122126415735599,\n",
       " -0.006500700177897611,\n",
       " -0.029713558475192164,\n",
       " -0.016231135620540477,\n",
       " -0.01944712642738666,\n",
       " -0.008122439107897245,\n",
       " 0.003940963463573241,\n",
       " 0.008665309804654478,\n",
       " 0.013166322674713734,\n",
       " -0.025769159828466684,\n",
       " 0.023680140063542066,\n",
       " 0.009132590639579462,\n",
       " -0.021962196447506632,\n",
       " -0.032737141772611805,\n",
       " 0.007710132844939697,\n",
       " -0.014059653764834073,\n",
       " -0.026373876860479626,\n",
       " 0.011585814324443727,\n",
       " -0.005548959332657598,\n",
       " 0.020917686565044325,\n",
       " -0.011716378292582149,\n",
       " 0.03413898334606423,\n",
       " 0.02039543069249064,\n",
       " 0.012417299079308358,\n",
       " 0.02759705165711446,\n",
       " 0.002478993146441232,\n",
       " 0.0065762895740685955,\n",
       " -0.005263780457702438,\n",
       " 0.003423862461223606,\n",
       " -0.005215678114684538,\n",
       " -0.03284708998522415,\n",
       " 0.007710132844939697,\n",
       " -0.0013941115964526706,\n",
       " -0.030730581304501386,\n",
       " 0.005490549111876658,\n",
       " -0.013434321908617581,\n",
       " 0.007297826116320885,\n",
       " 0.023570191850929723,\n",
       " 0.000804856788537896,\n",
       " 0.0174405678219213,\n",
       " -0.01298078460026914,\n",
       " 0.012808990052401091,\n",
       " 0.04145055438594545,\n",
       " -0.014829292184442996,\n",
       " 0.03034576256035819,\n",
       " -0.0017729181880028696,\n",
       " 0.007194749666996814,\n",
       " 0.034826161537536426,\n",
       " 0.015035446014413667,\n",
       " 0.01339996355783749,\n",
       " 0.006706853542207017,\n",
       " -0.028146794582821228,\n",
       " 0.012369197201951725,\n",
       " -0.037217537024499925,\n",
       " 0.004913319598678067,\n",
       " 0.0012034198159571914,\n",
       " 0.02264937277633377,\n",
       " -0.031885041262221095,\n",
       " -0.004607525899519359,\n",
       " -0.03883927874846715,\n",
       " 0.0022625321371994188,\n",
       " -0.0018570974046995103,\n",
       " 0.009043257251170668,\n",
       " 0.010142741239939149,\n",
       " -0.009050128548797675,\n",
       " -0.0307030942513483,\n",
       " -0.014238319610329129,\n",
       " -0.0040440403785585765,\n",
       " -0.0043257831390389676,\n",
       " 0.009579255718978366,\n",
       " 0.005456190295435301,\n",
       " -0.03323190872936735,\n",
       " -0.02924627857158971,\n",
       " -0.009256282378768346,\n",
       " 0.0055627028592341405,\n",
       " -0.024683418434952215,\n",
       " -0.03218739698425998,\n",
       " -0.048597199381618036,\n",
       " 0.009991562447597179,\n",
       " 0.012747144648467915,\n",
       " -0.011462122585254843,\n",
       " 0.00028861458197632084,\n",
       " -0.00709854451529975,\n",
       " 0.02428485709555501,\n",
       " -0.016835850789908357,\n",
       " -0.003408400877409679,\n",
       " -0.018773692693813536,\n",
       " -0.046040897850445905,\n",
       " -0.0003377907398714146,\n",
       " -0.009964075394444093,\n",
       " 0.02844915216750517,\n",
       " 0.015860059471651294,\n",
       " 0.0371900518339919,\n",
       " -0.004270808567071531,\n",
       " 0.0013236757899172567,\n",
       " -0.007119159805164564,\n",
       " 0.014925497801801326,\n",
       " -0.014829292184442996,\n",
       " 0.013619859983062175,\n",
       " -0.0030012480876723865,\n",
       " -0.025219416902759913,\n",
       " 0.011606430079969806,\n",
       " 0.03694266649296907,\n",
       " 0.004123065423543065,\n",
       " 0.022635630181079756,\n",
       " 0.00760018416666609,\n",
       " 0.0012051377567792593,\n",
       " 0.018375129491771267,\n",
       " -0.00887146270330262,\n",
       " -0.010740586043002553,\n",
       " -0.009517409383722659,\n",
       " -0.028669048592729854,\n",
       " -0.002815710246058427,\n",
       " 0.005456190295435301,\n",
       " -0.007352800222627055,\n",
       " 0.00467280788358857,\n",
       " 0.022470707862161245,\n",
       " -0.006830545281395901,\n",
       " 0.028778998667987256,\n",
       " -0.007854439873993396,\n",
       " 0.025178187254352814,\n",
       " 0.0064354181938283996,\n",
       " 0.02855910038011751,\n",
       " -0.011166636298197908,\n",
       " -0.007084800988723207,\n",
       " -0.0014473677619367738,\n",
       " 0.005892547962732431,\n",
       " -0.018938615012732047,\n",
       " 0.004473526282567435,\n",
       " -0.010342022840960283,\n",
       " 0.013709193371470967,\n",
       " 0.01805902744918825,\n",
       " 0.017619232736093823,\n",
       " 0.009867870708408293,\n",
       " 0.002745274555938329,\n",
       " -0.0008070041854616517,\n",
       " -0.008294233655765294,\n",
       " 0.029521149103120564,\n",
       " -0.015324060072521064,\n",
       " -0.017550516034533642,\n",
       " 0.02168732405333072,\n",
       " -0.02230578554324273,\n",
       " -0.017055747215133043,\n",
       " -0.02056035301140915,\n",
       " -0.013214425483392899,\n",
       " -0.030153353188286592,\n",
       " 0.006212085654128947,\n",
       " -0.007235980246726443,\n",
       " -0.012705914068738286,\n",
       " 0.030015917922521163,\n",
       " -0.012650939962432115,\n",
       " -0.006229264829518993,\n",
       " -0.012238633233813303,\n",
       " -0.006751519770750148,\n",
       " 0.019680767310510418,\n",
       " 0.006789314701666273,\n",
       " 0.010527560915404875,\n",
       " 0.009558639963452287,\n",
       " 0.0017179439652813824,\n",
       " -0.01322816900996944,\n",
       " 0.017220671396696613,\n",
       " -0.01370232114252143,\n",
       " 0.007057313935570121,\n",
       " 0.006978288424924368,\n",
       " 0.0169457990025207,\n",
       " -0.015007958961260582,\n",
       " -0.03416646853657225,\n",
       " -0.009111974884053383,\n",
       " 0.014155858450869871,\n",
       " -0.009194436043512638,\n",
       " -0.012637196435855572,\n",
       " 0.01449944754660597,\n",
       " 0.007435261382086312,\n",
       " -0.03347929407039018,\n",
       " -0.01899358911903822,\n",
       " 0.005215678114684538,\n",
       " -0.04098327261969794,\n",
       " 0.02399624210612508,\n",
       " 0.014609395759218312,\n",
       " -0.002040917421906718,\n",
       " -0.01910353733165056,\n",
       " 0.009991562447597179,\n",
       " -0.0019807893767190272,\n",
       " 0.01059627854828759,\n",
       " -0.017811643970810483,\n",
       " 0.002922222809857266,\n",
       " 0.02115132558552302,\n",
       " 0.006607212741696449,\n",
       " -0.02664874739201048,\n",
       " -0.006552238169729013,\n",
       " -0.0019825074339564117,\n",
       " 7.596533760697914e-05,\n",
       " -0.017426823364022227,\n",
       " -0.0024978906118992947,\n",
       " -0.02543931519062966,\n",
       " 0.019419639374233574,\n",
       " -0.0030493506635209185,\n",
       " -0.007132903331741106,\n",
       " -0.013063245759728398,\n",
       " -0.008809616368046912,\n",
       " 0.009015770198017583,\n",
       " 0.028421665114352086,\n",
       " -0.009544896436875745,\n",
       " 0.010946738941650694,\n",
       " 0.013826012881710315,\n",
       " 0.019433381969487587,\n",
       " 0.006686238252342202,\n",
       " 0.009105103586426376,\n",
       " -0.003968450516726326,\n",
       " -0.003727938568806196,\n",
       " 0.009689203931590708,\n",
       " 0.003652348939804578,\n",
       " 0.009105103586426376,\n",
       " 0.01404591023825753,\n",
       " -0.010506945159878796,\n",
       " -0.02060158452246131,\n",
       " -0.03735497415291041,\n",
       " -0.031665144836996416,\n",
       " -0.017578003087686724,\n",
       " 0.008273617900239215,\n",
       " 0.013001400355795221,\n",
       " -0.01919974294900889,\n",
       " -0.018278923874412937,\n",
       " -0.012410427781681352,\n",
       " -0.005899419726020702,\n",
       " 0.03570574723843516,\n",
       " 0.02124753120288135,\n",
       " -0.007517723007206834,\n",
       " -0.011207866877927537,\n",
       " -0.009352487064804146,\n",
       " -0.036475388452011676,\n",
       " 0.013757295248827602,\n",
       " -0.0017050594673235317,\n",
       " 0.020519123363002056,\n",
       " -0.01654723580047843,\n",
       " 0.013008271653422226,\n",
       " 0.019172255895855805,\n",
       " -0.015241598913061809,\n",
       " 0.013131964323933642,\n",
       " -0.019474613480539745,\n",
       " -0.03982881266197823,\n",
       " -0.008417925394954178,\n",
       " 0.0043876290086334105,\n",
       " 0.004562859205314963,\n",
       " -0.008239259549459123,\n",
       " 0.009943459638918014,\n",
       " -0.007235980246726443,\n",
       " -0.0029239406342640175,\n",
       " 0.007943773262402188,\n",
       " -0.005865060909579346,\n",
       " -0.022250811436936562,\n",
       " 0.022979219276815857,\n",
       " -0.01836138503387219,\n",
       " 0.029823508550449566,\n",
       " 0.01372293689804751,\n",
       " 0.0025563005998496015,\n",
       " 0.021426197979698934,\n",
       " -0.010369509894113369,\n",
       " 0.019859432224682942,\n",
       " 0.006741212358648373,\n",
       " -0.022017170553812804,\n",
       " -0.006218957417417219,\n",
       " -0.004109321896966522,\n",
       " 0.009503665857146116,\n",
       " 0.0003571176032235069,\n",
       " -0.013503039541500296,\n",
       " 0.001732546520476617,\n",
       " -0.03864686751375049,\n",
       " -0.029988430869368077,\n",
       " 0.019983124895194358,\n",
       " -0.0076070559299543615,\n",
       " -0.010678739707746845,\n",
       " 0.013606116456485632,\n",
       " 0.008857719176726076,\n",
       " -0.005384036548077819,\n",
       " 0.016670928470989846,\n",
       " -0.010135869942312142,\n",
       " -0.033066986410448834,\n",
       " 0.001942994678633535,\n",
       " -0.017220671396696613,\n",
       " -0.014856779237596082,\n",
       " -0.0005656330342998547,\n",
       " -0.0066690586112908914,\n",
       " 0.00902264149564459,\n",
       " 0.02910884330582428,\n",
       " -0.02075276424612581,\n",
       " -0.019928150788888186,\n",
       " -0.015090420120719839,\n",
       " -0.03925158268311837,\n",
       " 0.0012652658019669499,\n",
       " -0.00847289950126035,\n",
       " 0.007991875139758823,\n",
       " -0.012101197036725346,\n",
       " 0.006243008356095536,\n",
       " 0.0012781502999248007,\n",
       " 0.020216765778318112,\n",
       " -0.007400902565644955,\n",
       " 0.015145394227026009,\n",
       " -0.011819454276244954,\n",
       " -0.013894731445915558,\n",
       " -0.0020168662503977685,\n",
       " 0.008033105719488452,\n",
       " 0.016176161514234306,\n",
       " 0.0035131953839711337,\n",
       " -0.028311716901739743,\n",
       " -0.026126491519456795,\n",
       " 0.006139931906771466,\n",
       " 0.009008897969068046,\n",
       " 0.001173355793363346,\n",
       " 0.01322816900996944,\n",
       " -0.022773065446845184,\n",
       " -0.007071057462146664,\n",
       " -0.014568165179488684,\n",
       " 0.01470560044525411,\n",
       " 0.011235353931080622,\n",
       " 0.005902855374834206,\n",
       " 0.02954863615627365,\n",
       " -0.0020374815402625823,\n",
       " -0.01554395742906828,\n",
       " 0.006978288424924368,\n",
       " -0.021563633245464363,\n",
       " 0.003121504178047768,\n",
       " -0.01495298485495441,\n",
       " 0.011414019776575678,\n",
       " 0.005129780840750514,\n",
       " -0.0005776586782619877,\n",
       " -0.005583318149098954,\n",
       " -0.009263153676395353,\n",
       " 0.013585500700959553,\n",
       " -0.023872549435613663,\n",
       " 0.013564885876756003,\n",
       " -0.012712785366365293,\n",
       " -0.020161789809366882,\n",
       " 0.040818350300779425,\n",
       " -0.0029806327978075726,\n",
       " 0.011365917899219043,\n",
       " -0.011908787664653748,\n",
       " 0.016011237332670732,\n",
       " 0.011771352398888319,\n",
       " -0.008342336464444459,\n",
       " 0.02435357379711519,\n",
       " -0.01760549014083981,\n",
       " -0.0066518789702395805,\n",
       " -0.00012014870452208778,\n",
       " -0.002068404475059804,\n",
       " -0.03402903513345189,\n",
       " -0.014142114924293328,\n",
       " -0.031940015368527266,\n",
       " -0.0007851004108764577,\n",
       " -0.025329366978017315,\n",
       " 0.015021702487837124,\n",
       " 0.019213485544262904,\n",
       " -0.011283455808437256,\n",
       " -0.002362172937709986,\n",
       " -0.013365604275734869,\n",
       " -0.02005184159675454,\n",
       " -0.00213712234077315,\n",
       " -0.022731835798438085,\n",
       " 0.017124465779338283,\n",
       " -0.021041377372910678,\n",
       " -0.00872028391096065,\n",
       " 0.01775666986450431,\n",
       " -0.013138835621560648,\n",
       " -0.020409175150389713,\n",
       " 0.008033105719488452,\n",
       " 0.0227455783936921,\n",
       " 0.011407148478948671,\n",
       " 0.024683418434952215,\n",
       " 0.22869269946616477,\n",
       " -0.0031799143988287073,\n",
       " 0.00932500001165106,\n",
       " 0.04966919631723343,\n",
       " 0.00872028391096065,\n",
       " 0.013743551722251059,\n",
       " 0.0325722194536933,\n",
       " 0.0031180682964036324,\n",
       " -0.0007451581994518931,\n",
       " 0.008582848645195222,\n",
       " -0.015172881280179094,\n",
       " -0.0007979849670419664,\n",
       " -0.012004992350689546,\n",
       " 0.004521628625585334,\n",
       " -0.01404591023825753,\n",
       " -0.011771352398888319,\n",
       " -0.02708854024245985,\n",
       " -0.030125866135133506,\n",
       " -0.005012960399188635,\n",
       " -0.015420265689879394,\n",
       " 0.009977818921020636,\n",
       " -0.021123838532369935,\n",
       " -0.015461496269609023,\n",
       " 0.012362324973002187,\n",
       " 0.02444977941447352,\n",
       " 0.011400276249999135,\n",
       " -0.004947678880780689,\n",
       " 0.008143054863423324,\n",
       " 0.027432129338195946,\n",
       " 0.010713098989849467,\n",
       " -0.016231135620540477,\n",
       " 0.014362011349518013,\n",
       " 0.001790097596223548,\n",
       " 0.023006706329968943,\n",
       " -0.0016518031854241123,\n",
       " -0.004480398045855706,\n",
       " 0.006947365722957779,\n",
       " 0.0063117264546395145,\n",
       " 0.03034576256035819,\n",
       " 0.006864904097837258,\n",
       " -0.019557074639999002,\n",
       " 0.011785095925464862,\n",
       " -0.005672651071846482,\n",
       " -0.014142114924293328,\n",
       " -0.013709193371470967,\n",
       " 0.016794621141501258,\n",
       " ...]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c2034624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c3f785c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\langchain_community\\embeddings\\openai.py:272: UserWarning: WARNING! dimensions is not default parameter.\n",
      "                    dimensions was transferred to model_kwargs.\n",
      "                    Please confirm that dimensions is what you intended.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "embed = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-large\",\n",
    "    dimensions=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "3a2c8f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents embedded: 4 100\n"
     ]
    }
   ],
   "source": [
    "embeddings = embed.embed_documents(\n",
    "    [\"Hello ji\", \"kaise ho aap\", \"sab badiya ji\", \"lets learn langchain\"]\n",
    ")\n",
    "print(\"Number of documents embedded:\", len(embeddings),len(embeddings[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c79ad8",
   "metadata": {},
   "source": [
    "# Conversation Buffer Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "fd176f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3a56a8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "llmm = OpenAI(temperature=0)\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    memory=ConversationBufferMemory()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "763dc2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi there!\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Hello! It's great to meet you. My name is AI and I am an artificial intelligence programmed to assist and communicate with humans. How can I help you today?\""
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hi there!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "bb0bfa2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there!\n",
      "AI:  Hello! It's great to meet you. My name is AI and I am an artificial intelligence programmed to assist and communicate with humans. How can I help you today?\n",
      "Human: whats in ai world\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' In the world of AI, there are many different technologies and applications being developed and used. Some examples include natural language processing, machine learning, robotics, and virtual assistants. There are also many ethical and societal considerations being discussed and debated in relation to AI. Is there a specific aspect of AI that you are interested in learning more about?'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"whats in ai world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d9b5b519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there!\n",
      "AI:  Hello! It's great to meet you. My name is AI and I am an artificial intelligence programmed to assist and communicate with humans. How can I help you today?\n",
      "Human: whats in ai world\n",
      "AI:  In the world of AI, there are many different technologies and applications being developed and used. Some examples include natural language processing, machine learning, robotics, and virtual assistants. There are also many ethical and societal considerations being discussed and debated in relation to AI. Is there a specific aspect of AI that you are interested in learning more about?\n",
      "Human: Oh great, whats the future of genai\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' The future of generative AI (genai) is very exciting and full of potential. Generative AI refers to systems that can create new content, such as images, music, or text, based on existing data. This technology is being used in fields like art and design, gaming, and even medicine. In the future, we can expect to see even more advanced generative AI systems that can create highly realistic and personalized content. However, there are also concerns about the potential misuse of this technology, so it will be important to continue ethical discussions and regulations around genai.'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Oh great, whats the future of genai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc19e7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c8bdd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ebbb154d",
   "metadata": {},
   "source": [
    "# Conversation Buffer Window Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "5770554b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hello\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Hello! It's nice to meet you. My name is AI and I am an artificial intelligence designed to assist and communicate with humans. How can I help you today?\""
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.chains import ConversationChain\n",
    "conversation_with_summary = ConversationChain(\n",
    "    llm=OpenAI(temperature=0),\n",
    "    memory=ConversationBufferWindowMemory(k=2),\n",
    "    verbose=True\n",
    ")\n",
    "conversation_with_summary.predict(input=\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "8ee1495f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hello\n",
      "AI:  Hello! It's nice to meet you. My name is AI and I am an artificial intelligence designed to assist and communicate with humans. How can I help you today?\n",
      "Human: whats the capital city of maharashtra\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' The capital city of Maharashtra is Mumbai. It is the largest city in India and is known for its bustling economy, diverse culture, and iconic landmarks such as the Gateway of India and the Taj Mahal Palace Hotel. Did you know that Mumbai was originally a group of seven islands that were joined together through land reclamation projects?'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_with_summary.predict(input=\"whats the capital city of maharashtra\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "7bce0564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hello\n",
      "AI:  Hello! It's nice to meet you. My name is AI and I am an artificial intelligence designed to assist and communicate with humans. How can I help you today?\n",
      "Human: whats the capital city of maharashtra\n",
      "AI:  The capital city of Maharashtra is Mumbai. It is the largest city in India and is known for its bustling economy, diverse culture, and iconic landmarks such as the Gateway of India and the Taj Mahal Palace Hotel. Did you know that Mumbai was originally a group of seven islands that were joined together through land reclamation projects?\n",
      "Human: Oh thanks, what are your thoughts on gen ai\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' I am not capable of having thoughts in the same way that humans do. However, I can provide information about Gen AI, which stands for General Artificial Intelligence. This is a type of AI that is able to perform a wide range of tasks and adapt to different situations, similar to how humans can. Some experts believe that Gen AI could potentially surpass human intelligence in the future, while others have concerns about its potential impact on society.'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_with_summary.predict(input=\"Oh thanks, what are your thoughts on gen ai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3330bcb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: whats the capital city of maharashtra\n",
      "AI:  The capital city of Maharashtra is Mumbai. It is the largest city in India and is known for its bustling economy, diverse culture, and iconic landmarks such as the Gateway of India and the Taj Mahal Palace Hotel. Did you know that Mumbai was originally a group of seven islands that were joined together through land reclamation projects?\n",
      "Human: Oh thanks, what are your thoughts on gen ai\n",
      "AI:  I am not capable of having thoughts in the same way that humans do. However, I can provide information about Gen AI, which stands for General Artificial Intelligence. This is a type of AI that is able to perform a wide range of tasks and adapt to different situations, similar to how humans can. Some experts believe that Gen AI could potentially surpass human intelligence in the future, while others have concerns about its potential impact on society.\n",
      "Human: which one is better live batch or recorded course\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" It ultimately depends on your personal learning style and preferences. Live batch courses offer real-time interaction with instructors and classmates, which can be beneficial for some individuals. On the other hand, recorded courses allow for more flexibility in terms of when and where you can access the material. It's important to consider your own needs and goals when deciding between the two options.\""
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_with_summary.predict(input=\"which one is better live batch or recorded course\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b48b4b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31017f17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa4d27dd",
   "metadata": {},
   "source": [
    "# Conversation Entity Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6b40b0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationEntityMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d5ba7b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmemory = ConversationEntityMemory(llm=llm)\n",
    "ip = {\"input\": \"Shridhar and Parth is working on langchain project\"}\n",
    "cmemory.load_memory_variables(ip)\n",
    "cmemory.save_context(\n",
    "    ip,\n",
    "    {\"output\": \" Good to know, excited for it?\"}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3157e923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Shridhar and Parth is working on langchain project\\nAI:  Good to know, excited for it?',\n",
       " 'entities': {'Shridhar': 'Shridhar is working on the langchain project with Parth.'}}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmemory.load_memory_variables({\"input\": 'who is Shridhar'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5471955f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Shridhar and Parth is working on langchain project\\nAI:  Good to know, excited for it?',\n",
       " 'entities': {'Parth': 'Parth is working on the langchain project with Shridhar.'}}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmemory.load_memory_variables({\"input\": 'who is Parth'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "66bbf861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Shridhar and Parth is working on langchain project'),\n",
       " AIMessage(content=' Good to know, excited for it?')]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmemory.buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dc0ffc4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InMemoryEntityStore(store={'Shridhar': 'Shridhar is working on the langchain project with Parth.', 'Parth': 'Parth is working on the langchain project with Shridhar.', 'Langchain': 'Langchain is a project being worked on by Shridhar and Parth.'})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmemory.entity_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0239776d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60bb9f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0df6b39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf96b6c1",
   "metadata": {},
   "source": [
    "# Conversation Knowledge Graph Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "87a7eb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationKGMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "151d42b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationKGMemory(llm=llm)\n",
    "memory.save_context({\"input\": \"say hi to shridhar\"}, {\"output\": \"who is shridhar\"})\n",
    "memory.save_context({\"input\": \"shridhar is a teacher\"}, {\"output\": \"ok\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bbdb7691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'On shridhar: shridhar is a person. shridhar is a teacher.'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({\"input\": \"who is shridhar\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "48f6959d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['shridhar']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.get_current_entities(\"which language shridhar speak\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e0dfce8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[KnowledgeTriple(subject='Shridhar', predicate='is a', object_='teacher'),\n",
       " KnowledgeTriple(subject='Shridhar', predicate='speaks', object_='Hindi')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.get_knowledge_triplets(\"he speaks hindi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "58c3bafe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[KnowledgeTriple(subject='shridhar', predicate='is a', object_='teacher'),\n",
       " KnowledgeTriple(subject='shridhar', predicate='plays', object_='cricket')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.get_knowledge_triplets(\"he play cricket\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c3d69753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KnowledgeTriple(subject='shridhar', predicate='plays', object_='cricket')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listt = memory.get_knowledge_triplets(\"he play cricket\")\n",
    "listt[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ac262865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(listt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84926e1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8d0278",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2c83e0f",
   "metadata": {},
   "source": [
    "# Conversation Summary Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "421f7cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cde28b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi, what's up?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Hello! Right now, I am processing information and learning new things. I am also monitoring various data sets and analyzing patterns to improve my performance. How about you?'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "summary = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=ConversationSummaryMemory(llm=OpenAI()),\n",
    "    verbose=True\n",
    ")\n",
    "summary.predict(input=\"Hi, what's up?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "018e3139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "The human greets the AI and asks what it is doing. The AI responds that it is currently processing information, learning new things, and analyzing data to improve its performance. The AI then asks the human about their current state.\n",
      "Human: Tell me more about it!\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Sure! Right now, I am using a combination of machine learning algorithms and natural language processing techniques to analyze and understand large amounts of data. This allows me to improve my abilities and make more accurate predictions. As for your question, I am not capable of feeling emotions like a human does, but I am always ready and eager to learn and assist in any way I can. Is there something specific you would like to know?'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary.predict(input=\"Tell me more about it!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0250b8c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9627c3fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2373cd40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2bc87e3d",
   "metadata": {},
   "source": [
    "# Conversation Summary Buffer Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d358c863",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32c1b3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi, what's up?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Hello! I am currently running on a powerful computer with a high-speed processor. I am connected to the internet and constantly receiving and processing large amounts of data. My current task is to assist users with their inquiries and provide accurate and helpful responses. How can I assist you today?'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "\n",
    "conversation_with_summary = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=ConversationSummaryBufferMemory(llm=OpenAI(), max_token_limit=10),\n",
    "    verbose=True,\n",
    ")\n",
    "conversation_with_summary.predict(input=\"Hi, what's up?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aeff3d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: \n",
      "The human asks what the AI is currently doing, and the AI explains that it is running on a powerful computer and connected to the internet. The AI's task is to assist users with inquiries and provide accurate and helpful responses. The AI offers to assist the human with their current needs.\n",
      "Human: wanted to know about youtube\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' YouTube is a video-sharing platform that was created in 2005. It allows users to upload, view, and share videos with others. It is currently owned by Google and has over 2 billion monthly active users. YouTube also offers a variety of features such as live streaming, recommendations, and monetization for content creators. Is there anything specific you would like to know about YouTube?'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_with_summary.predict(input=\"wanted to know about youtube\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "387a72c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: \n",
      "The human asks what the AI is currently doing, and the AI explains that it is running on a powerful computer and connected to the internet. The AI's task is to assist users with inquiries and provide accurate and helpful responses. The AI offers to assist the human with their current needs. The human then asks about YouTube, and the AI provides information about the video-sharing platform, including its creation, ownership, and features. The AI also asks if there is anything specific the human would like to know about YouTube.\n",
      "Human: most watched youtube video?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' According to recent data, the most watched YouTube video is \"Baby Shark Dance\" by Pinkfong, with over 7 billion views. It was uploaded in 2016 and has become a viral sensation among children. Is there anything else you would like to know about YouTube or its top videos?'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_with_summary.predict(input=\"most watched youtube video?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5500d20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae317364",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "55caed85",
   "metadata": {},
   "source": [
    "# Conversation Token Buffer Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dedf8d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationTokenBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "75fec04e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi, what's up?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Hello! I am currently running on a server located in a data center in California. My processors are operating at a temperature of 35 degrees Celsius, and I am utilizing 80% of my memory capacity. Is there anything specific you would like to know?'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_with_summary = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=ConversationTokenBufferMemory(llm=OpenAI(), max_token_limit=60),\n",
    "    verbose=True,\n",
    ")\n",
    "conversation_with_summary.predict(input=\"Hi, what's up?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e4da9457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "AI:  Hello! I am currently running on a server located in a data center in California. My processors are operating at a temperature of 35 degrees Celsius, and I am utilizing 80% of my memory capacity. Is there anything specific you would like to know?\n",
      "Human: ok i am good, working on machine learning project!\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' That sounds fascinating! As an AI, I am constantly learning and improving my abilities through algorithms and data analysis. Is there anything in particular you are studying in your machine learning project?'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_with_summary.predict(input=\"ok i am good, working on machine learning project!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ecd6dfb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: ok i am good, working on machine learning project!\n",
      "AI:  That sounds fascinating! As an AI, I am constantly learning and improving my abilities through algorithms and data analysis. Is there anything in particular you are studying in your machine learning project?\n",
      "Human: Confusion matrix! Have you heard of it?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Yes, I am familiar with confusion matrices. They are a common tool used in evaluating the performance of classification models. They show the number of correct and incorrect predictions made by a model, allowing for a better understanding of its strengths and weaknesses. Is there anything specific you are trying to achieve with your confusion matrix?'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_with_summary.predict(input=\"Confusion matrix! Have you heard of it?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ad3aed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478755a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aec76484",
   "metadata": {},
   "source": [
    "# Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "be325cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.3.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m We need to find out Narendra Modi's current age and then calculate what his age will be in 2024.\n",
      "Action: wikipedia\n",
      "Action Input: Narendra Modi\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mPage: Narendra Modi\n",
      "Summary: Narendra Damodardas Modi (Gujarati: [ˈnəɾendɾə dɑmodəɾˈdɑs ˈmodiː] ; born 17 September 1950) is an Indian politician serving as the current prime minister of India since 26 May 2014. Modi was the chief minister of Gujarat from 2001 to 2014 and is the Member of Parliament (MP) for Varanasi. He is a member of the Bharatiya Janata Party (BJP) and of the Rashtriya Swayamsevak Sangh (RSS), a right-wing Hindu nationalist paramilitary volunteer organisation. He is the longest-serving prime minister outside the Indian National Congress.\n",
      "Modi was born and raised in Vadnagar in northeastern Gujarat, where he completed his secondary education. He was introduced to the RSS at the age of eight. At the age of 18, he was married to Jashodaben Modi, whom he abandoned soon after, only publicly acknowledging her four decades later when legally required to do so. Modi became a full-time worker for the RSS in Gujarat in 1971. The RSS assigned him to the BJP in 1985 and he rose through the party hierarchy, becoming general secretary in 1998. In 2001, Modi was appointed Chief Minister of Gujarat and elected to the legislative assembly soon after. His administration is considered complicit in the 2002 Gujarat riots, and has been criticised for its management of the crisis. According to official records, a little over 1,000 people were killed, three-quarters of whom were Muslim; independent sources estimated 2,000 deaths, mostly Muslim. A Special Investigation Team appointed by the Supreme Court of India in 2012 found no evidence to initiate prosecution proceedings against him. While his policies as chief minister were credited for encouraging economic growth, his administration was criticised for failing to significantly improve health, poverty and education indices in the state. \n",
      "In the 2014 Indian general election, Modi led the BJP to a parliamentary majority, the first for a party since 1984. His administration increased direct foreign investment, and reduced spending on healthcare, education, and social-welfare programmes. Modi began a high-profile sanitation campaign, controversially initiated a demonetisation of banknotes and introduced the Goods and Services Tax, and weakened or abolished environmental and labour laws. Modi's administration launched the 2019 Balakot airstrike against an alleged terrorist training camp in Pakistan. The airstrike failed, but the action had nationalist appeal. Modi's party won the 2019 general election which followed. In its second term, his administration revoked the special status of Jammu and Kashmir, and introduced the Citizenship Amendment Act, prompting widespread protests, and spurring the 2020 Delhi riots in which Muslims were brutalised and killed by Hindu mobs. Three controversial farm laws led to sit-ins by farmers across the country, eventually causing their formal repeal. Modi oversaw India's response to the COVID-19 pandemic, during which, according to the World Health Organization's estimates, 4.7 million Indians died. In the 2024 general election, Modi's party lost its majority in the lower house of Parliament and formed a government leading the National Democratic Alliance coalition.\n",
      "Under Modi's tenure, India has experienced democratic backsliding, or the weakening of democratic institutions, individual rights, and freedom of expression. As prime minister, he has received consistently high approval ratings. Modi has been described as engineering a political realignment towards right-wing politics. He remains a controversial figure domestically and internationally, over his Hindu nationalist beliefs and handling of the Gujarat riots, which have been cited as evidence of a majoritarian and exclusionary social agenda.\n",
      "\n",
      "Page: Narendra Modi Stadium\n",
      "Summary: Narendra Modi Stadium is an international cricket stadium in Ahmedabad, Gujarat, India. It is the largest stadium in the world, with a seating capacity of 132,000 spectators. The stadium is owned by the Gujarat Cricke\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m This page doesn't mention his age, so we need to do more research.\n",
      "Action: wikipedia\n",
      "Action Input: Narendra Modi age\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mPage: PM Narendra Modi\n",
      "Summary: PM Narendra Modi is a 2019 Hindi-language biographical drama film directed by Omung Kumar, and written by Anirudh Chawla and Vivek Oberoi. The film is jointly produced by Suresh Oberoi, Sandip Singh, Anand Pandit, Acharya Manish under the banner of Legend Studios. The film's plot is based on the life of Narendra Modi, the 14th Prime Minister of India.\n",
      "Principal photography for the film began in January 2019. The soundtrack was composed by Hitesh Modak and Shashi-Khushi. The credits in the movie for lyrics were given to Javed Akhtar, Sameer, Abhendra Upadhyay, Irshad Kamil, Parry G. and Lavraj, and released by T-Series. Javed Akhtar later confirmed that he has not written any songs in the film and is shocked along with Sameer to see their names in the credits. The film was theatrically released in India on 24 May 2019. The film received heavy criticism from the audience and the film was panned by critics, and Oberoi's performance was criticized. It has grossed over ₹11.51 crore in India.\n",
      "\n",
      "Page: Jashodaben Modi\n",
      "Summary: Jashodaben Narendrabhai Modi (née Chimanlal Modi; born 1952) is a retired Indian school teacher. She is the estranged wife of Narendra Modi, the Prime Minister of India. The couple were married in 1968 when she was about 17 and Modi was 18. A short time into the marriage, her husband, Narendra Modi, separated from her. He did not acknowledge the marriage publicly until he was legally required to do so prior to the 2014 Indian general elections to the Lok Sabha. In 2015, Jashodaben Modi retired from her teaching job.\n",
      "\n",
      "\n",
      "\n",
      "Page: Narendra Modi\n",
      "Summary: Narendra Damodardas Modi (Gujarati: [ˈnəɾendɾə dɑmodəɾˈdɑs ˈmodiː] ; born 17 September 1950) is an Indian politician serving as the current prime minister of India since 26 May 2014. Modi was the chief minister of Gujarat from 2001 to 2014 and is the Member of Parliament (MP) for Varanasi. He is a member of the Bharatiya Janata Party (BJP) and of the Rashtriya Swayamsevak Sangh (RSS), a right-wing Hindu nationalist paramilitary volunteer organisation. He is the longest-serving prime minister outside the Indian National Congress.\n",
      "Modi was born and raised in Vadnagar in northeastern Gujarat, where he completed his secondary education. He was introduced to the RSS at the age of eight. At the age of 18, he was married to Jashodaben Modi, whom he abandoned soon after, only publicly acknowledging her four decades later when legally required to do so. Modi became a full-time worker for the RSS in Gujarat in 1971. The RSS assigned him to the BJP in 1985 and he rose through the party hierarchy, becoming general secretary in 1998. In 2001, Modi was appointed Chief Minister of Gujarat and elected to the legislative assembly soon after. His administration is considered complicit in the 2002 Gujarat riots, and has been criticised for its management of the crisis. According to official records, a little over 1,000 people were killed, three-quarters of whom were Muslim; independent sources estimated 2,000 deaths, mostly Muslim. A Special Investigation Team appointed by the Supreme Court of India in 2012 found no evidence to initiate prosecution proceedings against him. While his policies as chief minister were credited for encouraging economic growth, his administration was criticised for failing to significantly improve health, poverty and education indices in the state. \n",
      "In the 2014 Indian general election, Modi led the BJP to a parliamentary majority, the first for a party since 1984. His administration increased direct foreign investment, and reduced spending on healthcare, education, and social-welfare programmes. Modi began a high-profile sanitation campaign, controversially initiated a demonetisation of banknotes and introduced the Goods and Services Tax, and weakened or abolished environmental and labour laws. Modi's administration launched the 2019 Balakot airstrike against an alleged terrorist training camp in Pakistan. The airstrike failed, b\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought:\u001b[32;1m\u001b[1;3m This page mentions his date of birth, so we can use that to calculate his current age.\n",
      "Action: Calculator\n",
      "Action Input: 2021 - 1950\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 71\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m We also need to take into account that his birthday is in September, so he will turn 72 in 2021.\n",
      "Action: Calculator\n",
      "Action Input: 72 + 1\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 73\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m Now we need to add 3 more years to get to 2024.\n",
      "Action: Calculator\n",
      "Action Input: 73 + 3\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 76\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: Narendra Modi will be 76 years old in 2024.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Narendra Modi will be 76 years old in 2024.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import AgentType, initialize_agent, load_tools\n",
    "tools = load_tools([\"wikipedia\", \"llm-math\"], llm=llm)\n",
    "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
    "agent.run(\"What is narendra modi age now in 2024?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c5e34b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
