{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7QG7sxmoCIvN"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UCK6vQ5QCQJe"
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('/Users/shridharmankar/finalreview.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "8u_yXh9dCmEE",
    "outputId": "bdcb9868-74c8-40b2-e5e9-877b949ce385"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/shridharmankar/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/shridharmankar/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "corpus = []\n",
    "for i in range(0, 50):\n",
    "  review = re.sub('[^a-zA-Z0-9]', ' ', dataset['review'][i])\n",
    "  review = review.lower()\n",
    "  review = review.split()\n",
    "  lm = WordNetLemmatizer()\n",
    "  all_stopwords = stopwords.words('english')\n",
    "  all_stopwords.remove('not')\n",
    "  review = [lm.lemmatize(word) for word in review if not word in set(all_stopwords)]\n",
    "  review = ' '.join(review)\n",
    "  corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "KpGWdrzGoAsL",
    "outputId": "a1d5020d-8005-4735-d4b9-ad99fb366534"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loved movie action best performance every actor', 'good movie blockbuster cinema', 'loved movie acting', 'best part acting awesome performance', 'total waste money', 'poor storyline bad performance lead', 'give 9 10 one 9 10 editing much fast except everything felt right place', 'first half slow boring', 'song best part movie liked', 'waste time money rubbish movie', 'give big zero waste', 'total overacting lead', 'doubt film changing face film industry every people put hard work effort', 'best indian movie nothing compared', 'movie known suspense thriller missing film really bad', 'good story great visuals best part many character film really increase curiosity audience acting awesome', 'worst movie decade giving 1 star 5', 'illogical action sequence usual', 'remarkable direction outstanding acting monumental narration unthinkable screenplay striking action sequence', 'meaningless appropriate boring', 'undoubtedly one worst big budget commercial movie seen', '3rd class acting screen work extremely disappointed', 'worst movie ever seen whole life boring nonsense', 'epic milestone film industry proud indian great movie best time', 'fabulous work done lead get bored watching movie screenplay background music cinematography amazing', 'movie win whole film industry', 'performance average actor literally walked talked acted like robot', 'movie ridiculous bad bad bad bad', 'garbage movie 0 5', 'performance mindblowing depiction ancient time perfect', 'fantastic movie writting best performance actor actress', 'superb flop movie ever seen life loser lead', 'stunt not important acting also required people not foolish waste movie together', 'movie horrible worst movie dont like one', 'lead acting like fool rubbish story bad', 'game changer mass cinematic brilliance', 'mind blowing experience watch masterpiece movie family enjoyed lot', 'literally background movie gave goosebump best movie decade', 'movie banned disrespectfull', 'movie masterpiece unique story absolutely stunning movie', 'worst movie ever seen whole life waste money', 'one powerful movie ever watched', 'movie disaster weak narrative bad acting', 'excellent story best screen play great direction awesome cinematography immpresive dialogue engaging lyric background score', 'flop movie worst worst worst film decade', 'best indian action film absolutely brilliant story direction', 'movie one favorite engaging music loved', 'action unnecessary dialoges boring', 'best best best great movie ever seen entire life', 'movie horrible worst movie recommend waste money shit']\n"
     ]
    }
   ],
   "source": [
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qroF7XcSCvY3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(179,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(corpus).toarray()\n",
    "y = dataset['label']\n",
    "X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qQXYM5VzDDDI"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "DS9oiDXXDRdI",
    "outputId": "77513c39-0ec6-4544-c056-26abe055b746"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Iif0CVhFDaMp",
    "outputId": "1266c3f2-d500-440e-d756-e0eabad504a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 0 0 0 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "Xj9IU6MxDnvo",
    "outputId": "43efba29-9811-4913-a085-8355ec1c02cb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "natural_language_processing.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
